<!--
=== 网页自动化HTML快照 (已清理) ===
URL: https://arxiv.org/search/advanced?advanced=1&terms-0-operator=AND&terms-0-term=Large+language&terms-0-field=title&classification-physics_archives=all&classification-include_cross_list=include&date-year=&date-filter_by=date_range&date-from_date=2025&date-to_date=2025&date-date_type=submitted_date&abstracts=show&size=50&order=-announced_date_first
最后更新: 2025-09-09T13:44:33.107713
原始大小: 84 KB
清理后大小: 67 KB
压缩率: 20.2%
生成时间: 2025-09-09T13:44:33.927172

清理说明:
- 已删除: <script>、<style>、<noscript> 标签
- 已删除: style属性、onclick等事件属性
- 已删除: CSS样式定义
- 保留: id、class、name、type等选择器属性
- 保留: 文本内容和DOM结构
-->
<!DOCTYPE html>
<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/><link href="...apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/><link href="...favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/><link href="...favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/><link href="...site.webmanifest" rel="manifest"/><link href="...safari-pinned-tab.svg" rel="mask-icon"/><link href="...favicon.ico" rel="shortcut icon"/><meta content="#b31b1b" name="msapplication-TileColor"/><meta content="images/icons/browserconfig.xml" name="msapplication-config"/><meta content="#b31b1b" name="theme-color"/><title>Advanced Search | arXiv e-print repository</title><link href="...arxivstyle.css" rel="stylesheet"/><link href="...bulma-tooltip.min.css" rel="stylesheet"/><link href="...search.css" rel="stylesheet"/></head><body><header><a class="is-sr-only" href="#main-container">Skip to main content</a><div class="attribution level is-marginless" role="banner"><div class="level-left"><a class="level-item" href="..."><img alt="Cornell University" aria-label="logo" src="...cornell-reduced-white-SMALL.svg"/></a></div><div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br/> the Simons Foundation, <a href="...ourmembers.html">member institutions</a>, and all contributors. <a href="...donate.html">Donate</a></span></p></div></div><div class="identity level is-marginless"><div class="level-left"><div class="level-item"><a aria-label="arxiv-logo" class="arxiv" href="..."><img alt="arxiv logo" aria-label="logo" src="...arxiv-logo-one-color-white.svg"/></a></div></div><div class="search-block level-right"><form action="https://arxiv.org/search" class="level-item mini-search" method="GET"><div class="field has-addons"><div class="control"><input aria-label="Search term or terms" class="input is-small" name="query" placeholder="Search..." type="text"/><p class="help"><a href="...help">Help</a> | <a href="...advanced">Advanced Search</a></p></div><div class="control"><div class="select is-small"><select aria-label="Field to search" name="searchtype"><option selected="selected" value="all">All fields</option><option value="title">Title</option><option value="author">Author</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select></div></div><input name="source" type="hidden" value="header"/><button class="button is-small is-cul-darker">Search</button></div></form></div></div><div class="container"><div aria-label="User menu" class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation"><a href="...login">Login</a></div></div></header><main class="container" id="main-container"><div class="level is-marginless"><div class="level-left"><h1 class="title is-clearfix"> Showing 1–50 of 6,493 results </h1></div><div class="level-right is-hidden-mobile"><span class="help"><a href="...releases">Search v0.5.6 released 2020-02-24</a></span></div></div><div class="content"><div class="columns"><div class="column is-two-thirds-tablet"><p>Query: <a href="...advanced?terms-0-operator=AND&amp;terms-0-term=Large+language&amp;terms-0-field=title&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2025&amp;date-to_date=2025&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first">order: -announced_date_first; size: 50; date_range: from 2025-01-01 to 2025-12-31; include_cross_list: True; terms: AND title=Large language</a></p><div class="buttons"><a class="button is-link" href="...advanced?terms-0-operator=AND&amp;terms-0-term=Large+language&amp;terms-0-field=title&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2025&amp;date-to_date=2025&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first">Refine query</a><a class="button" href="...advanced">New search</a></div></div><div class="column is-one-third-tablet is-hidden-mobile"><p class="has-text-right"><a href="...?order=-announced_date_first&amp;size=50">Simple Search</a></p></div></div><div class="level breathe-horizontal"><div class="level-left"><form action="/search/advanced" method="GET"><div><input id="advanced" name="advanced" type="hidden" value="1"/><ul id="terms"><li><label for="terms-0">Terms-0</label><table id="terms-0"><tbody><tr><th><label for="terms-0-term">Search term...</label></th><td><input id="terms-0-term" name="terms-0-term" type="text" value="Large language"/></td></tr><tr><th><label for="terms-0-operator">Operator</label></th><td><select id="terms-0-operator" name="terms-0-operator"><option selected="" value="AND">AND</option><option value="OR">OR</option><option value="NOT">NOT</option></select></td></tr><tr><th><label for="terms-0-field">Field</label></th><td><select id="terms-0-field" name="terms-0-field"><option selected="" value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="cross_list_category">Cross-list category</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="author_id">arXiv author ID</option><option value="all">All fields</option></select></td></tr></tbody></table></li></ul><table id="classification"><tbody><tr><th><label for="classification-computer_science">Computer Science (cs)</label></th><td><input id="classification-computer_science" name="classification-computer_science" type="checkbox" value="y"/></td></tr><tr><th><label for="classification-economics">Economics (econ)</label></th><td><input id="classification-economics" name="classification-economics" type="checkbox" value="y"/></td></tr><tr><th><label for="classification-eess">Electrical Engineering and Systems Science (eess)</label></th><td><input id="classification-eess" name="classification-eess" type="checkbox" value="y"/></td></tr><tr><th><label for="classification-mathematics">Mathematics (math)</label></th><td><input id="classification-mathematics" name="classification-mathematics" type="checkbox" value="y"/></td></tr><tr><th><label for="classification-physics">Physics</label></th><td><input id="classification-physics" name="classification-physics" type="checkbox" value="y"/></td></tr><tr><th><label for="classification-physics_archives">Physics Archives</label></th><td><select id="classification-physics_archives" name="classification-physics_archives"><option selected="" value="all">all</option><option value="astro-ph">astro-ph</option><option value="cond-mat">cond-mat</option><option value="gr-qc">gr-qc</option><option value="hep-ex">hep-ex</option><option value="hep-lat">hep-lat</option><option value="hep-ph">hep-ph</option><option value="hep-th">hep-th</option><option value="math-ph">math-ph</option><option value="nlin">nlin</option><option value="nucl-ex">nucl-ex</option><option value="nucl-th">nucl-th</option><option value="physics">physics</option><option value="quant-ph">quant-ph</option></select></td></tr><tr><th><label for="classification-q_biology">Quantitative Biology (q-bio)</label></th><td><input id="classification-q_biology" name="classification-q_biology" type="checkbox" value="y"/></td></tr><tr><th><label for="classification-q_finance">Quantitative Finance (q-fin)</label></th><td><input id="classification-q_finance" name="classification-q_finance" type="checkbox" value="y"/></td></tr><tr><th><label for="classification-statistics">Statistics (stat)</label></th><td><input id="classification-statistics" name="classification-statistics" type="checkbox" value="y"/></td></tr><tr><th><label for="classification-include_cross_list">Include cross-list</label></th><td><ul id="classification-include_cross_list"><li><input checked="" id="classification-include_cross_list-0" name="classification-include_cross_list" type="radio" value="include"/><label for="classification-include_cross_list-0">Include cross-listed papers</label></li><li><input id="classification-include_cross_list-1" name="classification-include_cross_list" type="radio" value="exclude"/><label for="classification-include_cross_list-1">Exclude cross-listed papers</label></li></ul></td></tr></tbody></table><table id="date"><tbody><tr><th><label for="date-filter_by">Filter by</label></th><td><ul id="date-filter_by"><li><input id="date-filter_by-0" name="date-filter_by" type="radio" value="all_dates"/><label for="date-filter_by-0">All dates</label></li><li><input id="date-filter_by-1" name="date-filter_by" type="radio" value="past_12"/><label for="date-filter_by-1">Past 12 months</label></li><li><input id="date-filter_by-2" name="date-filter_by" type="radio" value="specific_year"/><label for="date-filter_by-2">Specific year</label></li><li><input checked="" id="date-filter_by-3" name="date-filter_by" type="radio" value="date_range"/><label for="date-filter_by-3">Date range</label></li></ul></td></tr><tr><th><label for="date-year">Year</label></th><td><input id="date-year" name="date-year" type="text" value=""/></td></tr><tr><th><label for="date-from_date">From</label></th><td><input id="date-from_date" name="date-from_date" type="text" value="2025"/></td></tr><tr><th><label for="date-to_date">to</label></th><td><input id="date-to_date" name="date-to_date" type="text" value="2025"/></td></tr><tr><th><label for="date-date_type">Apply to</label></th><td><ul id="date-date_type"><li><input checked="" id="date-date_type-0" name="date-date_type" type="radio" value="submitted_date"/><label for="date-date_type-0">Submission date (most recent)</label></li><li><input id="date-date_type-1" name="date-date_type" type="radio" value="submitted_date_first"/><label for="date-date_type-1">Submission date (original)</label></li><li><input id="date-date_type-2" name="date-date_type" type="radio" value="announced_date_first"/><label for="date-date_type-2">Announcement date</label></li></ul></td></tr></tbody></table><input id="include_older_versions" name="include_older_versions" type="checkbox" value="y"/><ul id="abstracts"><li><input checked="" id="abstracts-0" name="abstracts" type="radio" value="show"/><label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"/><label for="abstracts-1">Hide abstracts</label></li></ul></div><div class="box field is-grouped is-grouped-multiline level-item"><div class="control"><span class="select is-small"><select id="size" name="size"><option value="25">25</option><option selected="" value="50">50</option><option value="100">100</option><option value="200">200</option></select></span><label for="size">results per page</label>. </div><div class="control"><label for="order">Sort results by</label><span class="select is-small"><select id="order" name="order"><option selected="" value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select></span></div><div class="control"><button class="button is-small is-link">Go</button></div></div></form></div></div><nav aria-label="pagination" class="pagination is-small is-centered breathe-horizontal" role="navigation"><a class="pagination-previous is-invisible" href="">Previous </a><a class="pagination-next" href="...advanced?advanced=1&amp;terms-0-operator=AND&amp;terms-0-term=Large+language&amp;terms-0-field=title&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2025&amp;date-to_date=2025&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50">Next </a><ul class="pagination-list"><li><a aria-label="Goto page 1" class="pagination-link is-current" href="...advanced?advanced=1&amp;terms-0-operator=AND&amp;terms-0-term=Large+language&amp;terms-0-field=title&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2025&amp;date-to_date=2025&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=0">1 </a></li><li><a aria-current="page" aria-label="Page 2" class="pagination-link" href="...advanced?advanced=1&amp;terms-0-operator=AND&amp;terms-0-term=Large+language&amp;terms-0-field=title&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2025&amp;date-to_date=2025&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50">2 </a></li><li><a aria-current="page" aria-label="Page 3" class="pagination-link" href="...advanced?advanced=1&amp;terms-0-operator=AND&amp;terms-0-term=Large+language&amp;terms-0-field=title&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2025&amp;date-to_date=2025&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=100">3 </a></li><li><a aria-current="page" aria-label="Page 4" class="pagination-link" href="...advanced?advanced=1&amp;terms-0-operator=AND&amp;terms-0-term=Large+language&amp;terms-0-field=title&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2025&amp;date-to_date=2025&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=150">4 </a></li><li><a aria-current="page" aria-label="Page 5" class="pagination-link" href="...advanced?advanced=1&amp;terms-0-operator=AND&amp;terms-0-term=Large+language&amp;terms-0-field=title&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2025&amp;date-to_date=2025&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=200">5 </a></li><li><span class="pagination-ellipsis">…</span></li></ul></nav><ol class="breathe-horizontal" start="1"><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06949">arXiv:2509.06949</a><span> [<a href="...2509.06949">pdf</a>, <a href="...2509.06949">ps</a>, <a href="...2509.06949">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span></div></div><p class="title is-5 mathjax"> Revolutionizing Reinforcement Learning Framework for Diffusion <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Wang%2C+Y">Yinjie Wang</a>, <a href="...?searchtype=author&amp;query=Yang%2C+L">Ling Yang</a>, <a href="...?searchtype=author&amp;query=Li%2C+B">Bowen Li</a>, <a href="...?searchtype=author&amp;query=Tian%2C+Y">Ye Tian</a>, <a href="...?searchtype=author&amp;query=Shen%2C+K">Ke Shen</a>, <a href="...?searchtype=author&amp;query=Wang%2C+M">Mengdi Wang</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06949v1-abstract-short"> We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training, and is applicable across different architectures. Equipped with a diffusion-based value model that enhances training stability, we demonstrate improved reasoning performance on complex math and coding tasks. Besides, it ca… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06949v1-abstract-full"> We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training, and is applicable across different architectures. Equipped with a diffusion-based value model that enhances training stability, we demonstrate improved reasoning performance on complex math and coding tasks. Besides, it can also be applied to adapt block-specific models to larger blocks, which improves sampling flexibility. Employing TraceRL, we derive a series of state-of-the-art diffusion language models, namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still consistently outperforms them across complex math reasoning tasks. TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical reasoning benchmarks. Through curriculum learning, we also derive the first long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1% relative accuracy gain. To facilitate reproducible research and practical applications, we release a comprehensive open-source framework for building, training, and deploying diffusion LLMs across diverse architectures. The framework integrates accelerated KV-cache techniques and inference engines for both inference and reinforcement learning, and includes implementations of various supervised fine-tuning and RL methods for mathematics, coding, and general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p><p class="comments is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Comments:</span><span class="has-text-grey-dark mathjax">Code and Models: https://github.com/Gen-Verse/dLLM-RL</span></p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06858">arXiv:2509.06858</a><span> [<a href="...2509.06858">pdf</a>, <a href="...2509.06858">ps</a>, <a href="...2509.06858">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Physics and Society">physics.soc-ph</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Adaptation and Self-Organizing Systems">nlin.AO</span></div></div><p class="title is-5 mathjax"> Disentangling Interaction and Bias Effects in Opinion Dynamics of <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Brockers%2C+V+C">Vincent C. Brockers</a>, <a href="...?searchtype=author&amp;query=Ehrlich%2C+D+A">David A. Ehrlich</a>, <a href="...?searchtype=author&amp;query=Priesemann%2C+V">Viola Priesemann</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06858v1-abstract-short"> Large Language Models are increasingly used to simulate human opinion dynamics, yet the effect of genuine interaction is often obscured by systematic biases. We present a Bayesian framework to disentangle and quantify three such biases: (i) a topic bias toward prior opinions in the training data; (ii) an agreement bias favoring agreement irrespective of the question; and (iii) an anchoring bias to… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06858v1-abstract-full"> Large Language Models are increasingly used to simulate human opinion dynamics, yet the effect of genuine interaction is often obscured by systematic biases. We present a Bayesian framework to disentangle and quantify three such biases: (i) a topic bias toward prior opinions in the training data; (ii) an agreement bias favoring agreement irrespective of the question; and (iii) an anchoring bias toward the initiating agent's stance. Applying this framework to multi-step dialogues reveals that opinion trajectories tend to quickly converge to a shared attractor, with the influence of the interaction fading over time, and the impact of biases differing between LLMs. In addition, we fine-tune an LLM on different sets of strongly opinionated statements (incl. misinformation) and demonstrate that the opinion attractor shifts correspondingly. Exposing stark differences between LLMs and providing quantitative tools to compare them to human subjects in the future, our approach highlights both chances and pitfalls in using LLMs as proxies for human behavior. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06838">arXiv:2509.06838</a><span> [<a href="...2509.06838">pdf</a>, <a href="...2509.06838">ps</a>, <a href="...2509.06838">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span></div></div><p class="title is-5 mathjax"> EPT Benchmark: Evaluation of Persian Trustworthiness in <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Mirbagheri%2C+M+R">Mohammad Reza Mirbagheri</a>, <a href="...?searchtype=author&amp;query=Mirkamali%2C+M+M">Mohammad Mahdi Mirkamali</a>, <a href="...?searchtype=author&amp;query=Arani%2C+Z+M">Zahra Motoshaker Arani</a>, <a href="...?searchtype=author&amp;query=Javeri%2C+A">Ali Javeri</a>, <a href="...?searchtype=author&amp;query=Sadeghzadeh%2C+A+M">Amir Mahdi Sadeghzadeh</a>, <a href="...?searchtype=author&amp;query=Jalili%2C+R">Rasool Jalili</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06838v1-abstract-short"> Large Language Models (LLMs), trained on extensive datasets using advanced deep learning architectures, have demonstrated remarkable performance across a wide range of language tasks, becoming a cornerstone of modern AI technologies. However, ensuring their trustworthiness remains a critical challenge, as reliability is essential not only for accurate performance but also for upholding ethical, cu… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06838v1-abstract-full"> Large Language Models (LLMs), trained on extensive datasets using advanced deep learning architectures, have demonstrated remarkable performance across a wide range of language tasks, becoming a cornerstone of modern AI technologies. However, ensuring their trustworthiness remains a critical challenge, as reliability is essential not only for accurate performance but also for upholding ethical, cultural, and social values. Careful alignment of training data and culturally grounded evaluation criteria are vital for developing responsible AI systems. In this study, we introduce the EPT (Evaluation of Persian Trustworthiness) metric, a culturally informed benchmark specifically designed to assess the trustworthiness of LLMs across six key aspects: truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We curated a labeled dataset and evaluated the performance of several leading models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and Qwen - using both automated LLM-based and human assessments. Our results reveal significant deficiencies in the safety dimension, underscoring the urgent need for focused attention on this critical aspect of model behavior. Furthermore, our findings offer valuable insights into the alignment of these models with Persian ethical-cultural values and highlight critical gaps and opportunities for advancing trustworthy and culturally responsible AI. The dataset is publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06813">arXiv:2509.06813</a><span> [<a href="...2509.06813">pdf</a>, <a href="...2509.06813">ps</a>, <a href="...2509.06813">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span></div></div><p class="title is-5 mathjax"> A Comparative Benchmark of <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models for Labelling Wind Turbine Maintenance Logs </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Malyi%2C+M">Max Malyi</a>, <a href="...?searchtype=author&amp;query=Shek%2C+J">Jonathan Shek</a>, <a href="...?searchtype=author&amp;query=McDonald%2C+A">Alasdair McDonald</a>, <a href="...?searchtype=author&amp;query=Biscaya%2C+A">Andre Biscaya</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06813v1-abstract-short"> Effective Operation and Maintenance (O&amp;M) is critical to reducing the Levelised Cost of Energy (LCOE) from wind power, yet the unstructured, free-text nature of turbine maintenance logs presents a significant barrier to automated analysis. Our paper addresses this by presenting a novel and reproducible framework for benchmarking Large Language Models (LLMs) on the task of classifying these complex… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06813v1-abstract-full"> Effective Operation and Maintenance (O&amp;M) is critical to reducing the Levelised Cost of Energy (LCOE) from wind power, yet the unstructured, free-text nature of turbine maintenance logs presents a significant barrier to automated analysis. Our paper addresses this by presenting a novel and reproducible framework for benchmarking Large Language Models (LLMs) on the task of classifying these complex industrial records. To promote transparency and encourage further research, this framework has been made publicly available as an open-source tool. We systematically evaluate a diverse suite of state-of-the-art proprietary and open-source LLMs, providing a foundational assessment of their trade-offs in reliability, operational efficiency, and model calibration. Our results quantify a clear performance hierarchy, identifying top models that exhibit high alignment with a benchmark standard and trustworthy, well-calibrated confidence scores. We also demonstrate that classification performance is highly dependent on the task's semantic ambiguity, with all models showing higher consensus on objective component identification than on interpretive maintenance actions. Given that no model achieves perfect accuracy and that calibration varies dramatically, we conclude that the most effective and responsible near-term application is a Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate and standardise data labelling for human experts, thereby enhancing O&amp;M data quality and downstream reliability analysis. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p><p class="comments is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Comments:</span><span class="has-text-grey-dark mathjax">Associated GitHub repository: https://github.com/mvmalyi/wind-farm-maintenance-logs-labelling-with-llms</span></p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06759">arXiv:2509.06759</a><span> [<a href="...2509.06759">pdf</a>, <a href="...2509.06759">ps</a>, <a href="...2509.06759">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span></div></div><p class="title is-5 mathjax"> Aligning <span class="search-hit mathjax">Large</span> Vision-<span class="search-hit mathjax">Language</span> Models by Deep Reinforcement Learning and Direct Preference Optimization </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Nguyen%2C+T+T">Thanh Thi Nguyen</a>, <a href="...?searchtype=author&amp;query=Wilson%2C+C">Campbell Wilson</a>, <a href="...?searchtype=author&amp;query=Dalins%2C+J">Janis Dalins</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06759v1-abstract-short"> Large Vision-Language Models (LVLMs) or multimodal large language models represent a significant advancement in artificial intelligence, enabling systems to understand and generate content across both visual and textual modalities. While large-scale pretraining has driven substantial progress, fine-tuning these models for aligning with human values or engaging in specific tasks or behaviors remain… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06759v1-abstract-full"> Large Vision-Language Models (LVLMs) or multimodal large language models represent a significant advancement in artificial intelligence, enabling systems to understand and generate content across both visual and textual modalities. While large-scale pretraining has driven substantial progress, fine-tuning these models for aligning with human values or engaging in specific tasks or behaviors remains a critical challenge. Deep Reinforcement Learning (DRL) and Direct Preference Optimization (DPO) offer promising frameworks for this aligning process. While DRL enables models to optimize actions using reward signals instead of relying solely on supervised preference data, DPO directly aligns the policy with preferences, eliminating the need for an explicit reward model. This overview explores paradigms for fine-tuning LVLMs, highlighting how DRL and DPO techniques can be used to align models with human preferences and values, improve task performance, and enable adaptive multimodal interaction. We categorize key approaches, examine sources of preference data, reward signals, and discuss open challenges such as scalability, sample efficiency, continual learning, generalization, and safety. The goal is to provide a clear understanding of how DRL and DPO contribute to the evolution of robust and human-aligned LVLMs. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p><p class="comments is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Comments:</span><span class="has-text-grey-dark mathjax">Accepted for publication in the Proceedings of the 8th International Conference on Algorithms, Computing and Artificial Intelligence (ACAI 2025)</span></p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06596">arXiv:2509.06596</a><span> [<a href="...2509.06596">pdf</a>, <a href="...2509.06596">ps</a>, <a href="...2509.06596">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span></div></div><p class="title is-5 mathjax"> HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Tong%2C+X">Xin Tong</a>, <a href="...?searchtype=author&amp;query=Lin%2C+Z">Zhi Lin</a>, <a href="...?searchtype=author&amp;query=Wang%2C+J">Jingya Wang</a>, <a href="...?searchtype=author&amp;query=Jin%2C+B">Bo Jin</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06596v1-abstract-short"> Large Language Models (LLMs) often produce hallucinations in retrieval-augmented or long-context generation, even when relevant evidence is present. This stems from two issues: head importance is treated as input-agnostic, and raw attention weights poorly reflect each token's true contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a parameter-free decoding framework that d… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06596v1-abstract-full"> Large Language Models (LLMs) often produce hallucinations in retrieval-augmented or long-context generation, even when relevant evidence is present. This stems from two issues: head importance is treated as input-agnostic, and raw attention weights poorly reflect each token's true contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a parameter-free decoding framework that directly addresses both challenges. HAVE introduces head-adaptive gating, which performs instance-level soft reweighing of attention heads, and value calibration, which augments attention with the magnitude of value vectors to approximate write-back contribution. Together, these modules construct token-level evidence aligned with model updates and fuse it with the LM distribution through a lightweight uncertainty-scaled policy. HAVE requires no finetuning and operates in a single forward pass, making it efficient and broadly applicable. Experiments across multiple QA benchmarks and LLM families demonstrate that HAVE consistently reduces hallucinations and outperforms strong baselines, including DAGCD, with modest overhead. The framework is transparent, reproducible, and readily integrates with off-the-shelf LLMs, advancing trustworthy generation in real-world settings. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06436">arXiv:2509.06436</a><span> [<a href="...2509.06436">pdf</a>, <a href="...2509.06436">ps</a>, <a href="...2509.06436">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span></div></div><p class="title is-5 mathjax"> Tree of Agents: Improving Long-Context Capabilities of <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models through Multi-Perspective Reasoning </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Yu%2C+S">Song Yu</a>, <a href="...?searchtype=author&amp;query=Xu%2C+X">Xiaofei Xu</a>, <a href="...?searchtype=author&amp;query=Deng%2C+K">Ke Deng</a>, <a href="...?searchtype=author&amp;query=Li%2C+L">Li Li</a>, <a href="...?searchtype=author&amp;query=Tian%2C+L">Lin Tian</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06436v1-abstract-short"> Large language models (LLMs) face persistent challenges when handling long-context tasks, most notably the lost in the middle issue, where information located in the middle of a long input tends to be underutilized. Some existing methods that reduce input have the risk of discarding key information, while others that extend context windows often lead to attention dispersion. To address these limit… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06436v1-abstract-full"> Large language models (LLMs) face persistent challenges when handling long-context tasks, most notably the lost in the middle issue, where information located in the middle of a long input tends to be underutilized. Some existing methods that reduce input have the risk of discarding key information, while others that extend context windows often lead to attention dispersion. To address these limitations, we propose Tree of Agents (TOA), a multi-agent reasoning framework that segments the input into chunks processed by independent agents. Each agent generates its local cognition, then agents dynamically exchange information for collaborative reasoning along tree-structured paths. TOA enables agents to probe different reasoning orders for multi-perspective understanding, effectively mitigating position bias and reducing hallucinations. To improve processing efficiency, we incorporate prefix-hash caching and adaptive pruning strategies, achieving significant performance improvements with comparable API overhead. Experiments show that TOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple baselines and demonstrates comparable performance to the latest and much larger commercial models, such as Gemini1.5-pro, on various long-context tasks. Code is available at https://github.com/Aireduce952/Tree-of-Agents. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p><p class="comments is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Comments:</span><span class="has-text-grey-dark mathjax">19 pages, 5 figures</span></p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06429">arXiv:2509.06429</a><span> [<a href="...2509.06429">pdf</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span></div></div><p class="title is-5 mathjax"> Analyzing the Instability of <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models in Automated Bug Injection and Correction </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Er%2C+M+B">Mehmet Bilal Er</a>, <a href="...?searchtype=author&amp;query=%C4%B0lhan%2C+N">Nagehan İlhan</a>, <a href="...?searchtype=author&amp;query=Kuran%2C+U">Umut Kuran</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06429v1-abstract-short"> The use of Large Language Models (LLMs) in software engineering tasks is growing, especially in the areas of bug fixing and code generation. Nevertheless, these models often yield unstable results; when executed at different times with the same input, they can generate radically different code. The consistency of LLMs in bug-fixing tasks has not yet been thoroughly assessed, despite the fact that… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06429v1-abstract-full"> The use of Large Language Models (LLMs) in software engineering tasks is growing, especially in the areas of bug fixing and code generation. Nevertheless, these models often yield unstable results; when executed at different times with the same input, they can generate radically different code. The consistency of LLMs in bug-fixing tasks has not yet been thoroughly assessed, despite the fact that this instability has typically been discussed in the literature in relation to code generation. The purpose of this study is to look into how unstable an LLM like ChatGPT is when it comes to fixing code bugs. We examine the structural, syntactic, and functional variations among several fix recommendations made in response to the same prompt using code samples with various error types. Additionally, we assess how instability is affected by the temperature settings (0, 0.5, and 1) used for the model's deterministic operation. For a total of 20 problems in the experimental analysis, the model produced three fix suggestions at each temperature value, comparing nine distinct outputs for each problem. The Syntax Similarity and Output Equivalence Rate (OER) metrics were used to assess the outputs' structural and functional consistency. The results demonstrate that the model's outputs become much more unstable and variable as the temperature rises, with high temperatures showing especially high rates of functional failure. According to syntax similarity analyses, the suggested fixes show notable structural differences at high temperatures but are fairly similar at low temperatures. The purpose of this study is to provide important methodological insights into how LLM-based error correction systems can be applied more consistently in software development processes while also casting doubt on their dependability. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06337">arXiv:2509.06337</a><span> [<a href="...2509.06337">pdf</a>, <a href="...2509.06337">ps</a>, <a href="...2509.06337">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span></div></div><p class="title is-5 mathjax"><span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models as Virtual Survey Respondents: Evaluating Sociodemographic Response Generation </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Zhao%2C+J">Jianpeng Zhao</a>, <a href="...?searchtype=author&amp;query=Yuan%2C+C">Chenyu Yuan</a>, <a href="...?searchtype=author&amp;query=Luo%2C+W">Weiming Luo</a>, <a href="...?searchtype=author&amp;query=Xie%2C+H">Haoling Xie</a>, <a href="...?searchtype=author&amp;query=Zhang%2C+G">Guangwei Zhang</a>, <a href="...?searchtype=author&amp;query=Quan%2C+S+J">Steven Jige Quan</a>, <a href="...?searchtype=author&amp;query=Yuan%2C+Z">Zixuan Yuan</a>, <a href="...?searchtype=author&amp;query=Wang%2C+P">Pengyang Wang</a>, <a href="...?searchtype=author&amp;query=Zhang%2C+D">Denghui Zhang</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06337v1-abstract-short"> Questionnaire-based surveys are foundational to social science research and public policymaking, yet traditional survey methods remain costly, time-consuming, and often limited in scale. This paper explores a new paradigm: simulating virtual survey respondents using Large Language Models (LLMs). We introduce two novel simulation settings, namely Partial Attribute Simulation (PAS) and Full Attribut… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06337v1-abstract-full"> Questionnaire-based surveys are foundational to social science research and public policymaking, yet traditional survey methods remain costly, time-consuming, and often limited in scale. This paper explores a new paradigm: simulating virtual survey respondents using Large Language Models (LLMs). We introduce two novel simulation settings, namely Partial Attribute Simulation (PAS) and Full Attribute Simulation (FAS), to systematically evaluate the ability of LLMs to generate accurate and demographically coherent responses. In PAS, the model predicts missing attributes based on partial respondent profiles, whereas FAS involves generating complete synthetic datasets under both zero-context and context-enhanced conditions. We curate a comprehensive benchmark suite, LLM-S^3 (Large Language Model-based Sociodemographic Survey Simulation), that spans 11 real-world public datasets across four sociological domains. Our evaluation of multiple mainstream LLMs (GPT-3.5/4 Turbo, LLaMA 3.0/3.1-8B) reveals consistent trends in prediction performance, highlights failure modes, and demonstrates how context and prompt design impact simulation fidelity. This work establishes a rigorous foundation for LLM-driven survey simulations, offering scalable and cost-effective tools for sociological research and policy evaluation. Our code and dataset are available at: https://github.com/dart-lab-research/LLM-S-Cube-Benchmark <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06307">arXiv:2509.06307</a><span> [<a href="...2509.06307">pdf</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span></div></div><p class="title is-5 mathjax"> Can AI Make Energy Retrofit Decisions? An Evaluation of <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Shu%2C+L">Lei Shu</a>, <a href="...?searchtype=author&amp;query=Zhao%2C+D">Dong Zhao</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06307v1-abstract-short"> Conventional approaches to building energy retrofit decision making suffer from limited generalizability and low interpretability, hindering adoption in diverse residential contexts. With the growth of Smart and Connected Communities, generative AI, especially large language models (LLMs), may help by processing contextual information and producing practitioner readable recommendations. We evaluat… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06307v1-abstract-full"> Conventional approaches to building energy retrofit decision making suffer from limited generalizability and low interpretability, hindering adoption in diverse residential contexts. With the growth of Smart and Connected Communities, generative AI, especially large language models (LLMs), may help by processing contextual information and producing practitioner readable recommendations. We evaluate seven LLMs (ChatGPT, DeepSeek, Gemini, Grok, Llama, and Claude) on residential retrofit decisions under two objectives: maximizing CO2 reduction (technical) and minimizing payback period (sociotechnical). Performance is assessed on four dimensions: accuracy, consistency, sensitivity, and reasoning, using a dataset of 400 homes across 49 US states. LLMs generate effective recommendations in many cases, reaching up to 54.5 percent top 1 match and 92.8 percent within top 5 without fine tuning. Performance is stronger for the technical objective, while sociotechnical decisions are limited by economic trade offs and local context. Agreement across models is low, and higher performing models tend to diverge from others. LLMs are sensitive to location and building geometry but less sensitive to technology and occupant behavior. Most models show step by step, engineering style reasoning, but it is often simplified and lacks deeper contextual awareness. Overall, LLMs are promising assistants for energy retrofit decision making, but improvements in accuracy, consistency, and context handling are needed for reliable practice. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06164">arXiv:2509.06164</a><span> [<a href="...2509.06164">pdf</a>, <a href="...2509.06164">ps</a>, <a href="...2509.06164">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span></div></div><p class="title is-5 mathjax"> Benchmarking Gender and Political Bias in <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Yang%2C+J">Jinrui Yang</a>, <a href="...?searchtype=author&amp;query=Han%2C+X">Xudong Han</a>, <a href="...?searchtype=author&amp;query=Baldwin%2C+T">Timothy Baldwin</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06164v1-abstract-short"> We introduce EuroParlVote, a novel benchmark for evaluating large language models (LLMs) in politically sensitive contexts. It links European Parliament debate speeches to roll-call vote outcomes and includes rich demographic metadata for each Member of the European Parliament (MEP), such as gender, age, country, and political group. Using EuroParlVote, we evaluate state-of-the-art LLMs on two tas… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06164v1-abstract-full"> We introduce EuroParlVote, a novel benchmark for evaluating large language models (LLMs) in politically sensitive contexts. It links European Parliament debate speeches to roll-call vote outcomes and includes rich demographic metadata for each Member of the European Parliament (MEP), such as gender, age, country, and political group. Using EuroParlVote, we evaluate state-of-the-art LLMs on two tasks -- gender classification and vote prediction -- revealing consistent patterns of bias. We find that LLMs frequently misclassify female MEPs as male and demonstrate reduced accuracy when simulating votes for female speakers. Politically, LLMs tend to favor centrist groups while underperforming on both far-left and far-right ones. Proprietary models like GPT-4o outperform open-weight alternatives in terms of both robustness and fairness. We release the EuroParlVote dataset, code, and demo to support future research on fairness and accountability in NLP within political contexts. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p><p class="comments is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Comments:</span><span class="has-text-grey-dark mathjax">The 8th International Conference on Natural Language and Speech Processing (Oral)</span></p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06100">arXiv:2509.06100</a><span> [<a href="...2509.06100">pdf</a>, <a href="...2509.06100">ps</a>, <a href="...2509.06100">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span></div></div><p class="title is-5 mathjax"> Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Cao%2C+K">Kefan Cao</a>, <a href="...?searchtype=author&amp;query=Wu%2C+S">Shuaicheng Wu</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06100v1-abstract-short"> Large language models (LLMs) are prone to catastrophic forgetting in sequential multi-task settings. Parameter regularization methods such as O-LoRA and N-LoRA alleviate task interference by enforcing low-rank subspace orthogonality, but they overlook the fact that conventional additive fine-tuning disrupts the intrinsic geometric structure of LLM parameters, limiting performance. Our key insight… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06100v1-abstract-full"> Large language models (LLMs) are prone to catastrophic forgetting in sequential multi-task settings. Parameter regularization methods such as O-LoRA and N-LoRA alleviate task interference by enforcing low-rank subspace orthogonality, but they overlook the fact that conventional additive fine-tuning disrupts the intrinsic geometric structure of LLM parameters, limiting performance. Our key insight is that the parameter space of LLMs possesses a geometric structure, which must be preserved in addition to enforcing orthogonality. Based on this, we propose Orthogonal Low-rank Adaptation in Lie Groups (OLieRA), which introduces Lie group theory into LLM fine-tuning: leveraging multiplicative updates to preserve parameter geometry while applying orthogonality constraints to task subspaces. Experiments demonstrate that OLieRA achieves state-of-the-art results on the Standard CL benchmark and remains among the top-performing methods in the Large Number of Tasks setting. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p><p class="comments is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Comments:</span><span class="has-text-grey-dark mathjax">13 pages, 3 figures</span></p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06093">arXiv:2509.06093</a><span> [<a href="...2509.06093">pdf</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Materials Science">cond-mat.mtrl-sci</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span></div></div><p class="title is-5 mathjax"><span class="search-hit mathjax">Language</span> Native Lightly Structured Databases for <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Model Driven Composite Materials Research </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Liu%2C+Y">Yuze Liu</a>, <a href="...?searchtype=author&amp;query=Zhang%2C+Z">Zhaoyuan Zhang</a>, <a href="...?searchtype=author&amp;query=Zeng%2C+X">Xiangsheng Zeng</a>, <a href="...?searchtype=author&amp;query=Zhang%2C+Y">Yihe Zhang</a>, <a href="...?searchtype=author&amp;query=Yu%2C+L">Leping Yu</a>, <a href="...?searchtype=author&amp;query=Wang%2C+L">Lejia Wang</a>, <a href="...?searchtype=author&amp;query=Yu%2C+X">Xi Yu</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06093v1-abstract-short"> Chemical and materials research has traditionally relied heavily on knowledge narrative, with progress often driven by language-based descriptions of principles, mechanisms, and experimental experiences, rather than tables, limiting what conventional databases and ML can exploit. We present a language-native database for boron nitride nanosheet (BNNS) polymer thermally conductive composites that c… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06093v1-abstract-full"> Chemical and materials research has traditionally relied heavily on knowledge narrative, with progress often driven by language-based descriptions of principles, mechanisms, and experimental experiences, rather than tables, limiting what conventional databases and ML can exploit. We present a language-native database for boron nitride nanosheet (BNNS) polymer thermally conductive composites that captures lightly structured information from papers across preparation, characterization, theory-computation, and mechanistic reasoning, with evidence-linked snippets. Records are organized in a heterogeneous database and queried via composite retrieval with semantics, key words and value filters. The system can synthesizes literature into accurate, verifiable, and expert style guidance. This substrate enables high fidelity efficient Retrieval Augmented Generation (RAG) and tool augmented agents to interleave retrieval with reasoning and deliver actionable SOP. The framework supplies the language rich foundation required for LLM-driven materials discovery. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06065">arXiv:2509.06065</a><span> [<a href="...2509.06065">pdf</a>, <a href="...2509.06065">ps</a>, <a href="...2509.06065">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span></div></div><p class="title is-5 mathjax"> KatotohananQA: Evaluating Truthfulness of <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models in Filipino </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Nery%2C+L+A">Lorenzo Alfred Nery</a>, <a href="...?searchtype=author&amp;query=Catignas%2C+R+D">Ronald Dawson Catignas</a>, <a href="...?searchtype=author&amp;query=Tiam-Lee%2C+T+J">Thomas James Tiam-Lee</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06065v1-abstract-short"> Large Language Models (LLMs) achieve remarkable performance across various tasks, but their tendency to produce hallucinations limits reliable adoption. Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet they are primarily available in English, leaving a gap in evaluating LLMs in low-resource languages. To address this, we present KatotohananQA, a Filipino translation o… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06065v1-abstract-full"> Large Language Models (LLMs) achieve remarkable performance across various tasks, but their tendency to produce hallucinations limits reliable adoption. Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet they are primarily available in English, leaving a gap in evaluating LLMs in low-resource languages. To address this, we present KatotohananQA, a Filipino translation of the TruthfulQA benchmark. Seven free-tier proprietary models were assessed using a binary-choice framework. Findings show a significant performance gap between English and Filipino truthfulness, with newer OpenAI models (GPT-5 and GPT-5 mini) demonstrating strong multilingual robustness. Results also reveal disparities across question characteristics, suggesting that some question types, categories, and topics are less robust to multilingual transfer which highlight the need for broader multilingual evaluation to ensure fairness and reliability in LLM usage. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p><p class="comments is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Comments:</span><span class="has-text-grey-dark mathjax">14 pages, 1 figure, 9 tables, 1 listing. To appear in Proceedings of NLPIR 2025</span></p></li><li class="arxiv-result"><div class="is-marginless"><p class="list-title is-inline-block"><a href="...2509.06052">arXiv:2509.06052</a><span> [<a href="...2509.06052">pdf</a>, <a href="...2509.06052">ps</a>, <a href="...2509.06052">other</a>] </span></p><div class="tags is-inline-block"><span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span><span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span></div></div><p class="title is-5 mathjax"> Empirical Study of Code <span class="search-hit mathjax">Large</span><span class="search-hit mathjax">Language</span> Models for Binary Security Patch Detection </p><p class="authors"><span class="has-text-black-bis has-text-weight-semibold">Authors:</span><a href="...?searchtype=author&amp;query=Li%2C+Q">Qingyuan Li</a>, <a href="...?searchtype=author&amp;query=Li%2C+B">Binchang Li</a>, <a href="...?searchtype=author&amp;query=Gao%2C+C">Cuiyun Gao</a>, <a href="...?searchtype=author&amp;query=Gao%2C+S">Shuzheng Gao</a>, <a href="...?searchtype=author&amp;query=Li%2C+Z">Zongjie Li</a></p><p class="abstract mathjax"><span class="has-text-black-bis has-text-weight-semibold">Abstract</span>: <span class="abstract-short has-text-grey-dark mathjax" id="2509.06052v1-abstract-short"> Security patch detection (SPD) is crucial for maintaining software security, as unpatched vulnerabilities can lead to severe security risks. In recent years, numerous learning-based SPD approaches have demonstrated promising results on source code. However, these approaches typically cannot be applied to closed-source applications and proprietary systems that constitute a significant portion of re… <a class="is-size-7">▽ More</a></span><span class="abstract-full has-text-grey-dark mathjax" id="2509.06052v1-abstract-full"> Security patch detection (SPD) is crucial for maintaining software security, as unpatched vulnerabilities can lead to severe security risks. In recent years, numerous learning-based SPD approaches have demonstrated promising results on source code. However, these approaches typically cannot be applied to closed-source applications and proprietary systems that constitute a significant portion of real-world software, as they release patches only with binary files, and the source code is inaccessible. Given the impressive performance of code large language models (LLMs) in code intelligence and binary analysis tasks such as decompilation and compilation optimization, their potential for detecting binary security patches remains unexplored, exposing a significant research gap between their demonstrated low-level code understanding capabilities and this critical security task. To address this gap, we construct a large-scale binary patch dataset containing \textbf{19,448} samples, with two levels of representation: assembly code and pseudo-code, and systematically evaluate \textbf{19} code LLMs of varying scales to investigate their capability in binary SPD tasks. Our initial exploration demonstrates that directly prompting vanilla code LLMs struggles to accurately identify security patches from binary patches, and even state-of-the-art prompting techniques fail to mitigate the lack of domain knowledge in binary SPD within vanilla models. Drawing on the initial findings, we further investigate the fine-tuning strategy for injecting binary SPD domain knowledge into code LLMs through two levels of representation. Experimental results demonstrate that fine-tuned LLMs achieve outstanding performance, with the best results obtained on the pseudo-code representation. <a class="is-size-7">△ Less</a></span></p><p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 September, 2025; <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025. </p></li></ol></div></main></body></html>